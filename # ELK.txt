# ELK 통계성 api

1.요구조건분석
2.기술선택
3. 핵심 - 구현과정에서의 고민과 해결책


1. 요구조건분석 a. 서비스개요
SNS와 같은 커뮤니티형 서비스
컨텐츠/업로더/즐기는사용자/어드민 도메인이 존재

b. 통계성 api 요구조건 
사용자통계와 컨텐츠통계정보
기간별 방문자수,현재기간내방문자수,이전기간내방문자수,증감률, 재방문률 등
컨텐츠 기간내 조회수, 증감률 등


2. 기술선택
전체적 프로세스 -MSA구조
1-4  데이터수집과정
5-6 통계성데이터처리과정

왜 ELK?
백엔드 메인이 NodeJS
하둡, 스파크는 노드를 제공하지않았음
search와 aggregation이 필요한 경우가 많을것이라 예상(ELK 의 elasticSearch기능)
빅데이터 프로세싱보다는 분석과, 시각화에 집중하였기때문에


logstash -> ElasticSearch -> Kibana
전처리 -> ->

리사h정의 ELK 유튜브 추천



3. 구현과정에서의 고민과 해결책
a 셋업
ELK는 세 조합으로서 서로다른 프로세스를 각각 셋업해서 유기적 동작 어려움 -> 도커 컨테이너로 관리 -> docker-elk
참고로 up전에 반드시 setup 실행해야함

b. 구현과정-로그데이터 형태결정
사용자 동작 발생 -> 이벤트기반로그발생 과정
수신해서 처리한 로직 내부에 logstash로 로그 전송하는 로직 추가할때 어떤 형태로 추가?
-> 로그를 기록할때 어떤 이벤트인지 정보를 명시

c. index이름 rolling하기
모든 도큐먼트를 거대한 하나의 index에 저장하지않고 무작위숫자와 문자열을 추가..

d. Frequency정보와 Recency 정보

e. elasticsearch 쿼리캐시
시작시점과 종료시점 범위가 커지면 elasticsearch가 직접 쿼리를 실행하는 동작에 부하가 예상 -> 별도의 통계전용데이터베이스에 시간,일단위로 결과를 저장

f. 다중타임존지원
다중타임존 지원하는 DBMS로 해결

g. 데이터 품질관리


h. api서버자체가 중단되는 경우




QNA
로그데이터 이미 정형화 되어있는데 왜 ELK?
-> 정형화된것처럼 보이지만 개별 로그 필드가 이벤트마다 달라졌기때문에 ELK에 쌓아놓고 나중에 정형화하여 DB에 저장하였음